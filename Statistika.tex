\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[slovene]{babel}
\usepackage{amsthm,amsfonts,amsmath,amssymb,url}
\usepackage{mathtools}
\usepackage{bm}
\usepackage{esvect}
\usepackage{bbm}


\textheight 210 true mm
\textwidth 146 true mm
\voffset=-17mm
\hoffset=-13mm

\newtheorem{Izrek}{{\sc Izrek}}[section]
\newtheorem{Trditev}[Izrek]{{\sc Trditev}}
\newtheorem{Posledica}[Izrek]{{\sc Posledica}}
\newtheorem{Definicija}[Izrek]{{\sc Definicija}}
\newtheorem{Zgled}[Izrek]{{\sc Zgled}}
\newtheorem{Opomba}[Izrek]{{\sc Opomba}}
\def\theIzrek{{\rm \arabic{section}.\arabic{Izrek}}}

\newenvironment{izrek}{\begin{Izrek}\sl}{\end{Izrek}}
\newenvironment{trditev}{\begin{Trditev}\sl}{\end{Trditev}}
\newenvironment{posledica}{\begin{Posledica}\sl}{\end{Posledica}}
\newenvironment{definicija}{\begin{Definicija}\rm }{\end{Definicija}}
\newenvironment{zgled}{\begin{Zgled}\rm }{\end{Zgled}}
\newenvironment{opomba}{\begin{Opomba}\rm }{\end{Opomba}}

\newenvironment{dokaz}[1][{\sc Dokaz}]{\begin{proof}[#1]\renewcommand*{\qedsymbol}{\(\blacksquare\)}}{\end{proof}}

\newcommand{\Mod}[1]{\hbox{ (mod } #1)}
\renewcommand\labelenumi{(\theenumi)}

\begin{document}
	
	\thispagestyle{empty}
	\begin{center}
		\begin{Large}
			{\bf Zapiski pri predmetu Statistika}
		\end{Large}
		
	\end{center}
	Minimalni katalog znanja, ki ga bom sproti dopolnjeval. Verjetno bom izpustil kakšen dokaz in pa kakšen zgled.
	\vfill
	\begin{center}
		Ljubljana, 2017 $\quad \quad $ Gregor Vavdi
	\end{center}
	\newpage
	\setcounter{page}{1}
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%Uvod%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\section{Motivacija}
	Kako bi "ocenili" verjetnost, da pri metu kovanca pade cifra?
	\\
	Izvedemo $n$ neodvisnih "enakih" (v istih razmerah, na enak način, pošteno oz.naključno) metov kovanca in iskano verjetnost ocenimo z razmerjem $\frac{\textnormal{število cifer}}{n}$.
	\\
	\\
	Igramo igro, kjer kroglico položimo v eno od treh škatel. Zmešamo škatle med seboj in poskušamo uganiti kje je kroglica. Če uganemo dobimo $10$, v nasprotnem primeru pa izgubimo $6$.
	\\
	\\
	Kako bi ocenili pričakovano vrednost te igre?
	\\
	Izvedemo $n$ neodvisnih slučajnih iger in pričakovano vrednost ene igre ocenimo z $\frac{\textnormal{skupni izkupiček}}{n}$.
	\\
	\\
	Zdi se nam, da mora z večjim vzorcem priti boljša ocena.
	\\
	\\
	V 18. stoletju je grof Buffon kovanec vrgel 4040-krat in dobil 2048 cifer. Ocenjena verjetnost cifre je $0.50689$.
	\\
	V 19. stoletju je Pason vrgel kovanec 12000-krat in dobil 6019 cifer. Ocenjena vrejetnost je $0.5016$.
	\\
	\\
	Aksiome verjetnosti zgradimo tako, da so naša mnenja glede vprašanj upravičena.
	
	\section{Konvergenca slučajnih spremenljivk in limitni izrek}
	\begin{Definicija}
		Naj bodo $X_1,X_2,X_3,\ldots $ slučajne spremenljivke, definirane na skupnem prostoru $\Omega$.
		\begin{enumerate}
			\item
			Pravimo, da zaporedje $\{X_n\}_n$ konvergira k $X$ v porazdelitvi, če $$\lim\limits_{n \to \infty}{P(X_n \le x)} = P(X\le x)$$
			za vsa tista realna števila $x$, v katerih je komulativna porazdelitvena funkcija slučajne spremenljivke $X$ zvezna.
			\item
			Pravimo, da zaporedje $\{X_n\}_n$ konvergira k $X$ \textbf{v verjetnosti}, če velja:
			$$\lim\limits_{n \to \infty}{P(|X_n - X|>\varepsilon)} = 0$$
			za vsak $\varepsilon > 0$.
			\item
			Pravimo, da zaporedje $\{X_n\}_n$ konvergira k $X$ \textbf{skoraj gotovo}, če je:
			$$P(\{\omega \in \Omega | \exists \lim\limits_{n \to \infty}{X_n(\omega) = X(\omega)}\}) = 1$$	
			$$\iff$$
			$$P(\lim_{n\to \infty}{Xn=X} )= 1$$
		\end{enumerate}
	\end{Definicija}
	\begin{Trditev}
		Iz konvergence 'skoraj gotovo' sledi konvergenca v verjetnosti.
	\end{Trditev}
	\begin{Trditev}
		(Neenakost Markova)
		\\
		Naj bo $X$ slučajna spremenljivka s pričakovano vrednostjo in $a>0$ pozitivna konstanta. Tedaj je:
		$$P(|X| \ge a) \le \frac{E[|X|]}{a}$$
	\end{Trditev}
	\begin{dokaz}
		Naj bo $a>0$. Pišemo $A =  \{|X| \ge a\} = \{\omega |\quad |X(\omega)| \ge a  \}$. Tedaj $|X| \ge a \cdot \mathcal{U}_A$. Sledi $E[|X|] \ge a \cdot P(A)$.
	\end{dokaz}
	\begin{Posledica}
		(Neenakost Čebiševa)
		\\
		Naj bo $X$ slučajna spremenljivka s (končno) disperzijo. Tedaj velja
		$$P(|X - E[X]|\ge \varepsilon) \le \frac{D(X)}{\varepsilon ^2}$$
		za vsako pozitivno število $\varepsilon$.
	\end{Posledica}
	\begin{dokaz}
		$$P(|X- E[X]| \ge \varepsilon) = P( (|X - E[X]|)^2 \le \varepsilon ^2) < \frac{E((X - E[X])^2)}{\varepsilon ^2} = \frac{D(X)}{\varepsilon ^2}$$
	\end{dokaz}
	\begin{Izrek}\label{izrek:SZVS}
	(Šibki zakon velikih števil)
	\\
	Naj bodo $X_1, X_2, \ldots \quad \Omega \to \mathbb{R}$ neodvisne in enako porazdeljene slučajne spremenljivke s pričakovano vrednostjo $\mu$ in (končnim) odklonom $\sigma$. Tedaj zaporedje "vzorčnih povprečij" 
	$$\frac{X_1 + X_2 + \ldots + X_n}{n}$$
	konvergira \textbf{v verjetnosti} h konstanti $\mu$.
	\end{Izrek}
	\begin{dokaz}
		Trdimo, da velja $\lim\limits_{n \to \infty}{P(|\frac{X_1+X_2+\ldots + X_n}{n}} - \mu| \ge \varepsilon) = 0$ za vsak pozitiven $\varepsilon > 0$. Pišimo $\bar{X} = \frac{X_1+\ldots + X_n}{n}$.
		$$P(|\bar{X} - \mu | > \varepsilon) \le P(|\bar{X} - \mu | \ge \varepsilon) \le \frac{D(\bar{X})}{\varepsilon ^2} = \frac{D(\frac{X_1+ \ldots + X_n}{n})}{\varepsilon ^2} = \frac{1}{n^2 \varepsilon ^2}D(X_1) + \ldots + D(X_n) = \frac{\sigma ^2 }{n \varepsilon ^2}$$
		Sledi, da rezultat konvergira proti $0$, ko gre $n$ v neskončnost.
	\end{dokaz}
	\begin{Opomba}
		Verjetnost kateregakoli konkretnega neskončnega zaporedja cifer in grbov je 0, ne glede na to, koliko je dejanska verjetnost posameznega meta $p\in (0,1)$.
	\end{Opomba}
	\begin{Opomba}
		(Česa šibki zakon velikih števil ne trdi.)
		\\
		Denimo, da je $p = \frac{1}{2}$. Beležimo število cifer po $n$ poskusih. \textbf{Ne velja}, da je število cifer po n poskusih večje od števila grbov 'približno polovici časa'.
		\\
		Zlahka je število cifer ves čas večje od števila grbov.
	\end{Opomba}
	\begin{Izrek}\label{izrek:KZVS}
		(Krepki zakon velikih števil)
		\\
		Naj bo $X_1, X_2, \ldots$ zaporedje neodvisnih in enako porazdeljenih slučajnih spremenljivk s končno pričakovano vrednostjo $E(X_i) \in \mathbb{R}$.
		Tedaj zaporedje "vzorčnih povprečij"
		$$\frac{X_1 + X_2 + \ldots + X_n}{n}$$
		konvergira k $E[X_i] =: \mu$ \textbf{skoraj gotovo}.
	\end{Izrek}
	\begin{Opomba}
	Končna pričakovana vrednost pomeni $E[|X_i|] < \infty$
	\end{Opomba}
	\begin{Zgled}
		Ponavljamo Bernoullijev poskus z verjetnostjo enice p. Tedaj skoraj gotovo velja:
		\begin{equation}\label{eq:zgled}
		\lim_{n\to \infty}{\frac{\textnormal{št. enic v n poskusih}}{n}} = p
		\end{equation}
		To pomeni: verjetnost tistih neskončnih zaporedij $( \omega_1, \omega_2, \ldots )$ za katere \eqref{eq:zgled} velja, je $1$.
	\end{Zgled}
	\begin{Opomba}
		Krepki zakon velikih števil je uzakonitev frekvenistične definicije (intuicije) v verjetnosti.
	\end{Opomba}
	\begin{Opomba}
		Iz izreka \ref{izrek:KZVS} sledi izrek \ref{izrek:SZVS}
	\end{Opomba}
	\subsection{Centralni limitni izrek}
	\begin{Izrek}
		Naj bodo $X_1, X_2, \ldots$ neodvisno enako porazedeljene Bernoullijevke ($B(1,p)$). Tedaj zaporedje \textbf{standardiziranih povprečij}
		$$\cfrac{\cfrac{X_1+X_2 + \ldots + X_n}{n} - p}{ \cfrac{\sqrt{p(1-p)}}{ \sqrt{n} } }  =
		 \frac{\sqrt{n}}{\sqrt{p(1-p)}} \left(  \cfrac{X_1+X_2 + \ldots + X_n}{n} - p \right)$$
		konvergira k standardni normalni porazdelitvi v porazdelitvi. 
		\\
		\\
		Z drugimi besedami: Če velja $Y_n \sim Bin(n,p)$ sledi:
		$$\frac{\sqrt{n}}{\sqrt{p(1-p)}} \left(  \cfrac{Y_n}{n} - p \right) \xrightarrow[n\to \infty]{\textnormal{v porazdelitvi}} \mathcal{N}(0,1)$$
		\end{Izrek}
	\begin{Opomba}
		Dokaz bomo izpustili.
		\\
		Za $p = \frac{1}{2}$ je dokazal leta 1733 De Moivre.
		\\
		Za splošen p ga je dokazal Laplace.
		\\
		Uporabljamo ga za aproksimacijo binomskih porazdelitev za velike n z normalnimi porazdelitvami.
		\\
		Ohlapno lahko rečemo:
		$$Bin(n,p)\sim \mathcal{N}(np,np(1-p))$$
		za velike n-je.
	\end{Opomba}
	\begin{Izrek}\label{izrek:CTI}
		(Centralni limitni izrek)
		\\
		Naj bodo $X_1, X_2, \ldots$ neodvisne, enako porazdeljene slučajne spremenljivke s končno disperzijo $\sigma^2$ in pričakovano vrednostjo $\mu$. Tedaj zaporedje standardiziranih vzorčnih povprečij:
		$$\cfrac{\cfrac{X_1+X_2 + \ldots + X_n}{n} - \mu}{ \cfrac{\sigma}{ \sqrt{n} } } $$
		konvergira v porazdelitvi k $\mathcal{N}(0,1)$.
	\end{Izrek}
\begin{Opomba}
	V statistiki izrek \ref{izrek:CTI} uporabljamo tipično v primerih, ko so $X_1, X_2, \ldots$ neodvisne replikacije preučevane slučajne spremenljivke X.
\end{Opomba}
\begin{Zgled}
	\textnormal{Ljubljanske mlekarne proizvajajo litrsko plastenko jogurta Mu $3,2$. 'Jamčijo', da ima taka plastenka 'v povprečju' $32$g maščob. Privzamemo tudi, da Ljubljanske mlekarne 'jamčijo', da je odlklon vsebnosti maščob $1,5$g.}
	\\
	\begin{enumerate}
		\item
		Ali znamo izračunati (ali oceniti) $P(X\in (31g, 33g))$, če je $X$ zvezna spremenljivka, ki predstavlja maso maščob v slučajno izbrani plastenki?
		\\
		\\
		\textnormal{V splošnem ne znamo odgovoriti, saj ne poznamo porazdelitve.}
		\item
		Naključno izberemo 100 takih plastenk in označimo $X_i$ maso maščob v i-ti plastenki. Ali znamo izračunati (ali oceniti)?
		\\
		\\
		\textnormal{Lahko ocenimo s pomočjo izreka} \ref{izrek:CTI}. \textnormal{Praktične izkušnje kažejo, da je $n= 100$ že dovolj veliko}
		\\
		$$\bar{X} = \frac{X_1 + X_2 + \ldots + X_n}{100} \Rightarrow P\left(\frac{\bar{X} - 32}{\frac{3}{2\sqrt{100}}} \in \left( \frac{31 -32}{\frac{3}{2\sqrt{100}}}, \frac{33 - 32}{\frac{3}{2\sqrt{100}}} \right)   \right) = \phi\left(\frac{20}{3}\right) \ - \;  \phi \left(\frac{-20}{3}\right) = 1 $$
		\item
		Kaj pa verjetnost $P(\bar{X} \in (31{,}9 ; 32{,}1))$? 
		\\
		$$ P(\bar{X} \in (31{,}9 ; 32{,}1)) = \phi\left(\frac{2}{3}\right) \ - \ \phi \left(\frac{-2}{3}\right) = 0,7486 - 0,2514 = 0,4972$$
	\end{enumerate}
\end{Zgled}
\section{Deskriptivna statistika}
	Deskriptivna (opisna) statistika poskuša povzeti oziroma predstaviti značilnosti danega nabora podatkov, ki ga razumemo kot populacija. Beseda 'statistika' v naslovu pomeni, število o katerem predpostavljamo značilnost, ki nas zanima. Formalneje je statistika funkcija, ki nabor podatkov priredi smiselno število s katerim povzamemo določeno lastnost.
\subsection{Osnovne opisne statistike}
\subsubsection{Kvantili}
\subsubsection{Aritmetična sredina}
\begin{Definicija}
	Naj bodo $X_1, \ldots ,X_N$ številske spremenljivke. Aritmetična sredina je:
	$$\frac{1}{N}\sum_{i = 1}^{N}X_i = \frac{1}{N}\sum_{j = 1}^{N}{f_j \cdot x_j} = \frac{f_1 \cdot x_1 + \ldots + f_N\cdot x_N}{f_1 + \ldots + f_N}$$
\end{Definicija}
\begin{Opomba}
	Zadnja enakost zgoraj je ravno $E[X]$, če na množici $\{1,2,3,\ldots, N \}$ vzamemo \textbf{enakomerno} verjetnost pri kateri je $P(X = x_j) = \frac{f_j}{N}$.
\end{Opomba}
\subsubsection{Modus}
\begin{Definicija}
	Modus je vrednost z največjo frekvenco, če obstaja. Če je taka ena sama, govorimo o \textbf{unimodalni} porazdelitvi. (tipično za unimodalnost zahtevamo še kaj več)
\end{Definicija}
\begin{Opomba}
	Modus ima bistveno večji pomen pri zveznih porazdelitvah oz. številskih spremenljivkah, pri katerih so načeloma možne vse vrednosti iz nekega intervala. Pri zveznih porazdelitvah bi za unimodalnost zahtevali en lokalni maksimum porazdelitvene gostote pri splošnješih pa en geometrijsko definiran prevoj komulativne porazdelitvene funkcije F.
\end{Opomba}
\subsubsection{Razmiki}
\begin{Definicija}
	\textbf{Variacijski razmik} je razlika med maksimalno in minimalno vrednostjo, pri katerih maksimalno razumemo kot zadnjo vrednost v ranžirni vrsti, minimalno pa kot prvo vrednost v ranžirni vrsti.
	$$ X_{max} - X_{min} = X_N - X_1$$
\end{Definicija}
\begin{Opomba}
	Pomankljivost: občutljivost na ekstremne vrednosti.
\end{Opomba}
	\textbf{Interkvartilni razmik} : $Q_{\frac{3}{4}} - Q_{\frac{1}{4}}$
	\\
	\\
	\textbf{Seminterkvartilni razmik} : $\cfrac{Q_{\frac{3}{4}} - Q_{\frac{1}{4}}}{2}$
\subsubsection{Odstopanje od srednjih vrednosti}
\subsubitem{Povprečni absolutni odklon od aritmetične sredine}
	$$\frac{1}{N}\sum_{i = 1}^{N}{|X_i - \bar{X}|} = \frac{1}{N}\sum_{j = 1}^{r}{|f_j \cdot x_j - \bar{X}|}$$
\subsubitem{Povprečni absolutni odklon od mediane}	
	$$\frac{1}{N}\sum_{i = 1}^{N}{|X_i - Me|} = \frac{1}{N}\sum_{j = 1}^{r}{|f_j \cdot x_j - Me|}$$
\subsubitem{Povprečno kvadratno odstopanje}
	$$\frac{1}{N}\sum_{i = 1}^{N}{(X_i - \bar{X})^2} = D(X) = Var(X)$$
\subsubitem{Standardni odklon}
	$$\sqrt{\frac{1}{N}\sum_{i = 1}^{N}{(X_i - \bar{X})^2}} = \frac{1}{\sqrt{N}}||(X_1, \ldots ,X_N) - (\bar{X},\ldots ,\bar{X}) || $$
\begin{Opomba}
	Evklidska razdalja med $(X_1, \ldots , X_N) $  in njegovo pravokotno projekcijo na premico $\{ t \cdot (1,1, \ldots, 1) | t\in \mathbb{R} \}$
\end{Opomba}	

Kvadratni odklon je ugoden za računanje (tako praktično in teoretično), ker je ustrezna razdalja porojena z skalarnim produktom.
\begin{Trditev}
	Naj bo $\sigma_1$ povprečni absolutni odklon in $\sigma_2 = \sigma$ standardni odklon. Potem velja:
	$$\sigma_1 \le \sigma \le  \sqrt{N} \cdot \sigma_1$$
\end{Trditev}
\begin{dokaz}
	Ocena $\sigma \le  \sqrt{N} \cdot \sigma_1$ sledi iz neenakosti $a_1^2 +\ldots + a_N^2 \le (a_1 + \ldots + a_N)^2$ za pozitivna števila $a_i = |X_i - \bar{X}| \quad i= 1,2,\ldots,N$
	\\
	Ocena $\sigma_1 \le \sigma$ je posledica Cauchy-Schwarzova neenakost. Naj bo $u = (a_1, \ldots, a_N) \quad   a_i = |X_i - \bar{X}|$ in $v= (1,\ldots, 1) \in \mathbb{R}^N$. Iz neenakosti sledi: $|<u,v>| \le||u|| \cdot ||v||$.
\end{dokaz}

\subsubsection{Povezanost dveh  številskih spremenljivk}
\begin{Definicija}
	Naj bosta $X_1, X_2, \ldots, X_N$ in $Y_1,Y_2,\ldots, Y_N$ številski spremenljivki, ki sta definirani na istem naboru podatkov oziroma populaciji. Kovarianca je:
	$$Cov(X,Y) = \frac{1}{N}\sum_{i = 1}^{N}{(X_i - \bar{X})\cdot (Y_i - \bar{Y})} = \frac{1}{N}\sum_{i = 1}^{N}{x_i \cdot y_i} - \left(\frac{1}{N}  \sum_{i = 1}^{N}{x_i}\right)\left( \frac{1}{N}\sum_{i = 1}^{N}{y_i}\right)$$
	
	Kot mera za jakost linearne povezanosti je kovarianca odvisna od variance posameznih spremenljivk. 'Pravo' (relativno) mero dobimo z normiranjem:
	$$\varphi(X,Y) = \frac{\cfrac{1}{N}\sum_{i = 1}^{N}{(X_i - \bar{X})\cdot (Y_i - \bar{Y})} }{\sigma_X - \sigma_Y}$$
	To je t.i. Pearsonov korelacijski koeficient. Iz Cauchy-Schwarzove neenakosti sledi $|\varphi(X,Y)| \le 1$.
\end{Definicija}
	\end{document}
